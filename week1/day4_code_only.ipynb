{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bee0370",
   "metadata": {},
   "source": [
    "### generative pre-trained transformer\n",
    "### more parameters= more context, more memory, more time\n",
    "### early days: neural netwroks trained at character level\n",
    "### middle ground: tokens, chunks of words, limited set, fragment of words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f20952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "tokens = encoding.encode(\"Hi my name is Agnes and I like reading romance novels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfddcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12194, 922, 1308, 382, 157967, 326, 357, 1299, 6085, 30327, 43813]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756e3ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12194 = Hi\n",
      "922 =  my\n",
      "1308 =  name\n",
      "382 =  is\n",
      "157967 =  Agnes\n",
      "326 =  and\n",
      "357 =  I\n",
      "1299 =  like\n",
      "6085 =  reading\n",
      "30327 =  romance\n",
      "43813 =  novels\n"
     ]
    }
   ],
   "source": [
    "for token_id in tokens:\n",
    "    token_text = encoding.decode([token_id])\n",
    "    print(f\"{token_id} = {token_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7c7ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d77708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e68790",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi! I'm Agnes!\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b2565a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Agnes! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890937d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a97446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have access to that information. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8e579",
   "metadata": {},
   "source": [
    "### every call to an LLM is completely STATELESS. It's a totally new call, every single time. As AI engineers, it's OUR JOB to devise techniques to give the impression that the LLM has a \"memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1652595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi! I'm Agnes!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi Agnes! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec438c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Agnes! How can I help you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bbfe7f",
   "metadata": {},
   "source": [
    "1. Every call to an LLM is stateless\n",
    "2. We pass in the entire conversation so far in the input prompt, every time\n",
    "3. This gives the illusion that the LLM has memory - it apparently keeps the context of the conversation\n",
    "4. But this is a trick; it's a by-product of providing the entire conversation, every time\n",
    "5. An LLM just predicts the most likely next tokens in the sequence; if that sequence contains \"My name is Agnes\" and later \"What's my name?\" then it will predict.. Agnes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd8be8",
   "metadata": {},
   "source": [
    "### context window: max number of tokens that the model can consider when generating the next token , includes original input prompt, subsequent conversation, latest input prompt and almost all the output prompt \n",
    "### governs how well model can remember references, context , and content \n",
    "- multi shot prompting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec9893",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
